version: '3.9'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  message-broker:
    image: confluentinc/cp-kafka:7.5.0
    container_name: message-broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://message-broker:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  data-storage:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.0
    container_name: data-storage
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  visualization:
    image: docker.elastic.co/kibana/kibana:8.13.0
    container_name: visualization
    ports:
      - "5601:5601"
    depends_on:
      - data-storage
    environment:
      - ELASTICSEARCH_HOSTS=http://data-storage:9200
      - xpack.security.enabled=false

  data-aggregator-agent:
    image: docker.elastic.co/beats/filebeat:8.13.0
    container_name: data-aggregator-agent
    user: root
    volumes:
      - ./data-aggregator/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /opt/threat-detection-lab/logs/suricata/ssh:/logs:ro
    command: ["--strict.perms=false"]
    depends_on:
      - message-broker

  raw-data-router:
    image: docker.elastic.co/logstash/logstash:8.13.0
    container_name: raw-data-router
    volumes:
      - ./data-aggregator/pipeline:/usr/share/logstash/pipeline:ro
    depends_on:
      - message-broker
      - data-storage

  data-normalizer:
    build:
      context: ./data-normalizer
    container_name: data-normalizer 
    depends_on:
      - message-broker
    restart: always

volumes:
  esdata:
